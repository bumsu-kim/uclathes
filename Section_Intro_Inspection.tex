\section{Introduction}
In this chapter, we discuss the inspection strategy for DFO methods, focusing on filling the significant gap between global and local optimization strategies.

When the objective function is non-convex and has spurious local minima, it is in general difficult to find the global minimum using local optimization methods.
Global optimization methods
In such cases, local optimization methods are often used to find a local minimum. However, the quality of the local minimum is not guaranteed, and it is often difficult to quantify how good the solution is.
Global optimization methods seek the absolute best solution throughout the entire solution space. While this ensures the optimal solution is found, these methods can be computationally intensive, particularly for high-dimensional problems. On the contrary, local optimization methods are geared towards finding a suitable solution within a localized area of the solution space. Although efficient, these methods may overlook the global optimum if it is located outside a certain neighborhood.

We delve into the dichotomy between these two optimization strategies and discuss the $R$-local optimization approach \cite{chen2019run}, designed to bridge this gap. $R$-local optima lie between local and global optima, and often ensures a satisfactory solution quality by providing a definable radius for the solution's local neighborhood.

We also explore how $R$-local optimization interacts with DFO methods. Despite their advantages, $R$-local optimization methods can be computationally expensive, particularly when the cost of sampling the objective function is not significantly cheaper than the gradient. However, in the context of DFO, the addition of inspections may not substantially impact the overall sample complexity.

Our proposed framework directs local DFO methods towards an $R$-local minimum using a similar number of additional queries, up to a constant factor, to those the method would typically consume \emph{per iteration}. This algorithm that doesn't rely on a global surrogate model, which can be computationally demanding in high-dimensional scenarios.


\subsection{The gap between global optimization and local optimization}
The majority of the optimization methods are either global optimization or local optimization methods. They approach these problems in very different ways, which creates a gap between them. 

\paragraph{Global Optimization} This class of methods aims to find the absolute best solution (up to a small tolerance) in the \emph{entire} solution space for an optimization problem. In other words, it searches for the overall minimum or maximum. The techniques used for global optimization are typically exhaustive, as they have to explore the entire problem space to ensure they have found the best possible solution up to the tolerance. This is because there may be many local optima, but only one (or a few) global optima. As a result, these methods can be computationally expensive, particularly for complex, high-dimensional problems.

\paragraph{Local Optimization} This class of methods, on the other hand, focuses on finding a good solution in a neighborhood, no matter how small it is, of a specific point in the solution space. This does not necessarily mean that the solution will be the best overall; instead, it means that there is no better solution in some vicinity of the found one. Thus, local optimization methods can be faster and less computationally expensive than global ones, but they may miss the global optimum if it lies outside of the selected neighborhood.

\paragraph{Gap between these two types of optimization} The gap can be understood through the following perspectives.

Global optimization guarantees the best solution, while local optimization only guarantees the best solution within a local neighborhood. However, the size of the neighborhood is not known or controllable.

Due to the need to explore the entire solution space, global optimization usually requires much more computational effort, causing much longer running time, than local optimization.

In practice, the choice between local and global optimization often depends on the specific problem, the resources available, and the acceptable trade-offs. For low-dimensional problems where it is crucial to find the absolute best solution, global optimization becomes necessary. However, for many problems, a solution that is ``good enough'' is sufficient. 

Local methods, despite only producing local solutions, may be preferred and sometimes are only the choice due to their efficiency. 
To improve the solution quality of local methods, meta-heuristics were introduced. They include using multiple starting points, simulated annealing, genetic algorithms that allow occasional moves in the worse direction, etc.
However, neither local methods nor their meta-heuristic improvements could quantify how ``good enough'' their solutions are.

\paragraph{Filling the gap by $R$-local optimization}
According to \cite{chen2019run}, 
an $R$-local minimizer is a type of local minimizer that specifies a radius of the local neighborhood around the minimizer.

More specifically, suppose we would like to minimize a function $f: \mathbb{R}^n \rightarrow \mathbb{R}$. We say that $x^\star\in\mathbb{R}^n$ is an $R$-local minimizer of $f$ if  that $x^\star$ is a  minimizer of $f$ in the closed ball ${x \in \mathbb{R}^n: \|x - x^\star\| \leq R}$.
This means $x^\star$ is a local minimizer in the neighborhood of radius $R$ around it. 

The concept of an $R$-local minimizer is often used when we want to guarantee the solution found to have a sufficient quality in a vicinity of a defined size. This can be helpful when the global minimizer cannot be easily found or when the function is too complex to optimize over its entire domain. The value of $R$ could be chosen based on some prior knowledge or through a process of trial and error.

\subsection{DFO and \$R\$-local optimization}
$R$-local optimization offers clear advantages over purely local methods in terms of discovering better solutions. However, it often incurs a higher computational cost, specifically requiring \BK{$\mathcal{O}(s \exp({O(d')}))$ samples for $s$ blocks of dimension $d'$ as shown in \cite{chen2019run}}.
This can become prohibitively expensive in certain scenarios\BK{, particularly when the cost of sampling the objective function and its gradient is approximately equal}. However, in derivative-free optimization, unless there are special structures (such as sparse gradients described in \cite{cai2020zeroth}), an additional factor of $d$, compared to its gradient-based counterpart, in the sample complexity is unavoidable. Consequently, performing inspections may not significantly impact the overall sample complexity, but only up to a constant factor.
